{
  "hash": "7c04f7a79afba63487ab8577d648b2a8",
  "result": {
    "markdown": "---\ntitle: \"Reticulate handling of NA's\"\nauthor: Daniel Falbel\ndate: \"2023-07-26\"\n---\n\n\nThere's room for improving how [reticulate](https://github.com/rstudio/reticulate) \nhandles missing values when converting between R and Python (pandas) data.frames.\nThis documents highlights the current behavior and takes inspiration on \nPandas <-> Arrow casts to propose improvements.\n\n## Current behavior\n\nThe following data.frame contains `NA`'s in the 4 most used data types in R.\nWe use `tibble::as_tibble()` to show the data.frame as it better displays the data\ntypes.\n\n\n::: {.cell paged.print='false'}\n\n```{.r .cell-code}\ndf <- data.frame(\n  bool = c(NA, TRUE, FALSE),\n  int = c(NA, 1L, 2L),\n  num = c(NA, 0.1, 0.2),\n  char = c(NA, \"a\", \"b\")\n)\ntibble::as_tibble(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 4\n  bool    int   num char \n  <lgl> <int> <dbl> <chr>\n1 NA       NA  NA   <NA> \n2 TRUE      1   0.1 a    \n3 FALSE     2   0.2 b    \n```\n:::\n:::\n\nNow casting into a pandas data frame. We see the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_df <- reticulate::r_to_py(df)\n```\n:::\n\n\n- For **bool**: `NA` became `TRUE` which is quite unexpected.\n- For **int**: `NA` became the largest possible integer. This is also unexpected.\n  However pandas default integer data type does not support `NA`'s and in theory\n  one must cast them to float.\n- For **num**: we got a `NaN`, which is the default missing value in Pandas,\n  even though an [experimental `pd.NA`](https://pandas.pydata.org/docs/user_guide/missing_data.html#missing-data-na)\n  value.\n- For **char**, we get NA as a character, which is also very unlikely to be the best\n  way to handle the conversion. \n  \n  \n### Getting values back into R\n\nCasting back the pandas data.frame into R, we get:\n\n\n::: {.cell paged.print='false'}\n\n```{.r .cell-code}\nreticulate::py_to_r(p_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   bool int num char\n1  TRUE  NA  NA   NA\n2  TRUE   1 0.1    a\n3 FALSE   2 0.2    b\n```\n:::\n:::\n\nIt mostly works, besides that the missing boolean value is lost.\n\n## How others do it\n\nreticulate is not the only library that needs to convert tables with such types\nthat happen to contain missing values into pandas data frames. We looked into how [Arrow](https://arrow.apache.org/docs/python/index.html) and \n[Polars](https://github.com/pola-rs/polars) work in such cases. Both libraries \nsupport missing values via an explicit `NULL` value. Polars is based on Arrow, so\nthere shouldn't exist many differences compared to Arrow besides some additional\nhandling of `NaN`s.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pyarrow as pa\n\nb = pa.array([None, True, False])\ni = pa.array([None, 1, 2])\nn = pa.array([None, 0.1, 0.2])\nc = pa.array([None, \"a\", \"b\"])\n\nat = pa.table([b, i, n, c], names=[\"bool\", \"int\", \"num\", \"char\"])\n```\n:::\n\n\nAnd this is the result of the cast:\n\n\n::: {.cell}\n\n```{.python .cell-code}\np_df = at.to_pandas()\np_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    bool  int  num  char\n0   None  NaN  NaN  None\n1   True  1.0  0.1     a\n2  False  2.0  0.2     b\n```\n:::\n\n```{.python .cell-code}\np_df.dtypes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nbool     object\nint     float64\nnum     float64\nchar     object\ndtype: object\n```\n:::\n:::\n\nNote that:\n\n- **bool** and **char** were cast into object types. The object data type in Pandas\n  is used for columns with mixed types. \n  One possible downside of this approach is that `NA`s become bool after any comparison.\n  It also cast to `False` (or 0) when you sum a column containing a `None`.\n  \n\n  ::: {.cell}\n  \n  ```{.python .cell-code}\n  p_df['bool'] & True\n  ```\n  \n  ::: {.cell-output .cell-output-stdout}\n  ```\n  0    False\n  1     True\n  2    False\n  Name: bool, dtype: bool\n  ```\n  :::\n  \n  ```{.python .cell-code}\n  p_df['bool'] | True\n  ```\n  \n  ::: {.cell-output .cell-output-stdout}\n  ```\n  0    False\n  1     True\n  2     True\n  Name: bool, dtype: bool\n  ```\n  :::\n  \n  ```{.python .cell-code}\n  p_df['bool'].sum()\n  ```\n  \n  ::: {.cell-output .cell-output-stdout}\n  ```\n  1\n  ```\n  :::\n  \n  ```{.python .cell-code}\n  p_df['bool'].isna()\n  ```\n  \n  ::: {.cell-output .cell-output-stdout}\n  ```\n  0     True\n  1    False\n  2    False\n  Name: bool, dtype: bool\n  ```\n  :::\n  :::\n\n  \n- **int** has been cast into a 'float64' type. This reflects Pandas default approach\n  too, since integer values can't represent `NaN`s (the default missing value).\n  This approach seems reasonable for reticulate to consider - specially considering\n  how R is flexible in general with numerics and integers.\n  \n- **num**: the default missing value (`NaN`) is used.\n\n### What happens with round trip casts\n\nIt seems that from the above it's hard to get back the same arrow table that\nwas first converted. Let's try:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npa.Table.from_pandas(p_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npyarrow.Table\nbool: bool\nint: double\nnum: double\nchar: string\n----\nbool: [[null,true,false]]\nint: [[null,1,2]]\nnum: [[null,0.1,0.2]]\nchar: [[null,\"a\",\"b\"]]\n```\n:::\n:::\n\nThis works quite fine. The only information that has been lost is the data type\nof the integer column, that has been transformed into a float.\n\nTODO: figure out how arrow does this. Does it walk trough pandas `object` columns,\nand if it's constant besides the NULL, it uses that data type?\n\n### Using Pandas nullable data types\n\nArrow supports using Pandas nullable data types with:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\ndtype_mapping = {\n    pa.int8(): pd.Int8Dtype(),\n    pa.int16(): pd.Int16Dtype(),\n    pa.int32(): pd.Int32Dtype(),\n    pa.int64(): pd.Int64Dtype(),\n    pa.uint8(): pd.UInt8Dtype(),\n    pa.uint16(): pd.UInt16Dtype(),\n    pa.uint32(): pd.UInt32Dtype(),\n    pa.uint64(): pd.UInt64Dtype(),\n    pa.bool_(): pd.BooleanDtype(),\n    pa.float32(): pd.Float32Dtype(),\n    pa.float64(): pd.Float64Dtype(),\n    pa.string(): pd.StringDtype(),\n}\n\np_df_nullable = at.to_pandas(types_mapper=dtype_mapping.get)\n```\n:::\n\nIN such cases, the round trip cast also works perfectly:\n\n\n::: {.cell}\n\n```{.python .cell-code}\npa.Table.from_pandas(p_df_nullable)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npyarrow.Table\nbool: bool\nint: int64\nnum: double\nchar: string\n----\nbool: [[null,true,false]]\nint: [[null,1,2]]\nnum: [[null,0.1,0.2]]\nchar: [[null,\"a\",\"b\"]]\n```\n:::\n:::\n\n\n\n### Arrow -> Pandas -> R?\n\nOne question that came up is what happens if we take the Arrow table (that natively)\ncontaining missing values, cast into pandas and then into R. Can reticulate correctly\ninfer data types?\n\n\n::: {.cell paged.print='false'}\n\n```{.r .cell-code}\ntibble::as_tibble(reticulate::py$p_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 4\n  bool        int   num char     \n  <list>    <dbl> <dbl> <list>   \n1 <NULL>      NaN NaN   <NULL>   \n2 <lgl [1]>     1   0.1 <chr [1]>\n3 <lgl [1]>     2   0.2 <chr [1]>\n```\n:::\n:::\n\n\nIt seems reasonable, but we don't simplify the columns types which Arrow does \nnicely. \n\nWhat if we get the Pandas table that uses the nullable data types:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreticulate::py$p_df_nullable\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in format.data.frame(if (omit) x[seq_len(n0), , drop = FALSE] else x, :\ncorrupt data frame: columns will be truncated or padded with NAs\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                            bool\n1 <BooleanArray>\\n[<NA>, True, False]\\nLength: 3, dtype: boolean\n2                                                           <NA>\n3                                                           <NA>\n                                                    int\n1 <IntegerArray>\\n[<NA>, 1, 2]\\nLength: 3, dtype: Int64\n2                                                  <NA>\n3                                                  <NA>\n                                                           num\n1 <FloatingArray>\\n[<NA>, 0.1, 0.2]\\nLength: 3, dtype: Float64\n2                                                         <NA>\n3                                                         <NA>\n                                                       char\n1 <StringArray>\\n[<NA>, 'a', 'b']\\nLength: 3, dtype: string\n2                                                      <NA>\n3                                                      <NA>\n```\n:::\n:::\n\n\nDoesn't work.\n\n### Polars\n\nWe don't expect many differences in behavior between Arrow and Polars, so we just\nquickly print the conversion results:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport polars as pl\npl_df = pl.DataFrame({\n  'bool': [None, True, False],\n  'int':  [None, 1, 2],\n  'num':  [None, 0.1, 0.2],\n  'char': [None, \"a\", \"b\"],\n})\npl_df\n```\n\n::: {.cell-output-display}\n```{=html}\n<div><style>\n.dataframe > thead > tr > th,\n.dataframe > tbody > tr > td {\n  text-align: right;\n}\n</style>\n<small>shape: (3, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>bool</th><th>int</th><th>num</th><th>char</th></tr><tr><td>bool</td><td>i64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>true</td><td>1</td><td>0.1</td><td>&quot;a&quot;</td></tr><tr><td>false</td><td>2</td><td>0.2</td><td>&quot;b&quot;</td></tr></tbody></table></div>\n```\n:::\n:::\n\nConverting into pandas\n\n\n::: {.cell}\n\n```{.python .cell-code}\np_df = pl_df.to_pandas()\np_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    bool  int  num  char\n0   None  NaN  NaN  None\n1   True  1.0  0.1     a\n2  False  2.0  0.2     b\n```\n:::\n\n```{.python .cell-code}\np_df.dtypes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nbool     object\nint     float64\nnum     float64\nchar     object\ndtype: object\n```\n:::\n:::\n\nAnd getting back into polars:\n\n\n::: {.cell paged.print='false'}\n\n```{.python .cell-code}\nprint(pl.DataFrame(p_df))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshape: (3, 4)\n┌───────┬──────┬──────┬──────┐\n│ bool  ┆ int  ┆ num  ┆ char │\n│ ---   ┆ ---  ┆ ---  ┆ ---  │\n│ bool  ┆ f64  ┆ f64  ┆ str  │\n╞═══════╪══════╪══════╪══════╡\n│ null  ┆ null ┆ null ┆ null │\n│ true  ┆ 1.0  ┆ 0.1  ┆ a    │\n│ false ┆ 2.0  ┆ 0.2  ┆ b    │\n└───────┴──────┴──────┴──────┘\n```\n:::\n:::\n\nSame as with Arrow.\n\n### PySpark\n\nWe also looked at how Spark casts its DataFrames, that supports nullable data types\ninto Pandas data frames and back.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport findspark\nfindspark.init()\nimport pyspark as ps\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n\ns_df = spark.createDataFrame([\n  (None, None, None, None),\n  (True, 1, 0.1, \"a\"),\n  (False, 2, 0.2, \"b\")], \n  [\"bool\", \"int\", \"num\", \"char\"]\n  )\ns_df\n```\n\n::: {.cell-output-display}\n```{=html}\n```\n:::\n\n```{.python .cell-code}\ns_df.head(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[Row(bool=None, int=None, num=None, char=None), Row(bool=True, int=1, num=0.1, char='a'), Row(bool=False, int=2, num=0.2, char='b')]\n```\n:::\n:::\n\n\nNow collect into a pandas data frame:\n\n\n::: {.cell}\n\n```{.python .cell-code}\np_df = s_df.toPandas()\np_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    bool  int  num  char\n0   None  NaN  NaN  None\n1   True  1.0  0.1     a\n2  False  2.0  0.2     b\n```\n:::\n\n```{.python .cell-code}\np_df.dtypes\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nbool     object\nint     float64\nnum     float64\nchar     object\ndtype: object\n```\n:::\n:::\n\nIt looks like PySpark is using the same behavior as Arrow (and Polars) which is to\nuse objects for booleans and chars, representing the null with Python `None`. Integers\nare converted into floats and then use `NaN` for representing the missing value.\n\nNow going back to spark:\n\n\n::: {.cell}\n\n```{.python .cell-code}\ns_df = spark.createDataFrame(p_df)\ns_df\n```\n\n::: {.cell-output-display}\n```{=html}\n```\n:::\n\n```{.python .cell-code}\ns_df.head(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[Row(bool=None, int=nan, num=nan, char=None), Row(bool=True, int=1.0, num=0.1, char='a'), Row(bool=False, int=2.0, num=0.2, char='b')]\n```\n:::\n:::\n\n\nWhen going back, the types are simplifed (object -> boolean, object -> string).\nDifferently from Arrow, `NaN` are kept and not converted into `None` or the Spark\n`null` value.\n\nCan we use the Pandas's nullable datatypes when casting from Spark? I couldn't\nfind it, although you can:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nspark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\nspark.createDataFrame(s_df.toPandas()).head(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[Row(bool=None, int=None, num=None, char=None), Row(bool=True, int=1.0, num=0.1, char='a'), Row(bool=False, int=2.0, num=0.2, char='b')]\n```\n:::\n:::\n\n\nAnd now, you get `None` instead of `NaN`s to represent missing values for integers\nand numeric. Although this is tricky because it would wrongly convert real `NaN`s. into\nnulls.\n\nBy setting this feature to `True`, you also get the casts from nullable pandas data types:\n\n\n::: {.cell}\n\n```{.python .cell-code}\nspark.createDataFrame(p_df_nullable).head(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[Row(bool=None, int=None, num=None, char=None), Row(bool=True, int=1, num=0.1, char='a'), Row(bool=False, int=2, num=0.2, char='b')]\n```\n:::\n:::\n\n\n## Future actions\n\nGiven this analysis, I think it make sense to make the following changes to reticulate:\n\n- We should provide an option to use Pandas nullable data types when casting from\n  R to Pandas. And maybe - maybe - this should be the default. Given the current\n  behavior, it seems that this is much safer.\n  \n- We should support casting from Pandas nullable data types to R.\n\n- Similar to how Arrow and Spark works, when converting Pandas `object` columns to R,\n  we should simply their data type if it only contains `None` and another scalar type.\n\n::: {.callout-note collapse=\"true\"}\n## Session Info \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.2.2 (2022-10-31)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.4.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] Rcpp_1.0.11          rstudioapi_0.14      knitr_1.43          \n [4] magrittr_2.0.3       lattice_0.20-45      rlang_1.1.1         \n [7] fastmap_1.1.1        fansi_1.0.4          tools_4.2.2         \n[10] grid_4.2.2           xfun_0.39            png_0.1-8           \n[13] utf8_1.2.3           cli_3.6.1            htmltools_0.5.4     \n[16] yaml_2.3.7           digest_0.6.31        tibble_3.2.1        \n[19] lifecycle_1.0.3      Matrix_1.5-1         htmlwidgets_1.6.0   \n[22] vctrs_0.6.2          glue_1.6.2           evaluate_0.19       \n[25] rmarkdown_2.19       compiler_4.2.2       pillar_1.9.0        \n[28] reticulate_1.30-9000 jsonlite_1.8.7       pkgconfig_2.0.3     \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nreticulate::py_config()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npython:         /Users/dfalbel/Documents/venv/reticulate/bin/python\nlibpython:      /Users/dfalbel/.pyenv/versions/3.9.16/lib/libpython3.9.dylib\npythonhome:     /Users/dfalbel/Documents/venv/reticulate:/Users/dfalbel/Documents/venv/reticulate\nversion:        3.9.16 (main, Dec 20 2022, 15:32:28)  [Clang 14.0.0 (clang-1400.0.29.202)]\nnumpy:          /Users/dfalbel/Documents/venv/reticulate/lib/python3.9/site-packages/numpy\nnumpy_version:  1.24.0\n\nNOTE: Python version was forced by RETICULATE_PYTHON\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npd.show_versions()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nINSTALLED VERSIONS\n------------------\ncommit           : 8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7\npython           : 3.9.16.final.0\npython-bits      : 64\nOS               : Darwin\nOS-release       : 22.5.0\nVersion          : Darwin Kernel Version 22.5.0: Thu Jun  8 22:22:20 PDT 2023; root:xnu-8796.121.3~7/RELEASE_ARM64_T6000\nmachine          : arm64\nprocessor        : arm\nbyteorder        : little\nLC_ALL           : None\nLANG             : en_US.UTF-8\nLOCALE           : en_US.UTF-8\n\npandas           : 1.5.2\nnumpy            : 1.24.0\npytz             : 2022.7\ndateutil         : 2.8.2\nsetuptools       : 58.1.0\npip              : 22.0.4\nCython           : None\npytest           : None\nhypothesis       : None\nsphinx           : None\nblosc            : None\nfeather          : None\nxlsxwriter       : None\nlxml.etree       : None\nhtml5lib         : None\npymysql          : None\npsycopg2         : None\njinja2           : 3.1.2\nIPython          : 8.14.0\npandas_datareader: None\nbs4              : None\nbottleneck       : None\nbrotli           : None\nfastparquet      : None\nfsspec           : 2023.4.0\ngcsfs            : None\nmatplotlib       : 3.7.2\nnumba            : None\nnumexpr          : None\nodfpy            : None\nopenpyxl         : None\npandas_gbq       : None\npyarrow          : 12.0.1\npyreadstat       : None\npyxlsb           : None\ns3fs             : None\nscipy            : None\nsnappy           : None\nsqlalchemy       : None\ntables           : None\ntabulate         : 0.9.0\nxarray           : None\nxlrd             : None\nxlwt             : None\nzstandard        : None\ntzdata           : None\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\npl.show_versions()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n--------Version info---------\nPolars:              0.18.6\nIndex type:          UInt32\nPlatform:            macOS-13.4.1-arm64-arm-64bit\nPython:              3.9.16 (main, Dec 20 2022, 15:43:04) \n[Clang 14.0.0 (clang-1400.0.29.202)]\n\n----Optional dependencies----\nadbc_driver_sqlite:  <not installed>\nconnectorx:          <not installed>\ndeltalake:           <not installed>\nfsspec:              2023.4.0\nmatplotlib:          3.7.2\nnumpy:               1.24.0\npandas:              1.5.2\npyarrow:             12.0.1\npydantic:            <not installed>\nsqlalchemy:          <not installed>\nxlsx2csv:            <not installed>\nxlsxwriter:          <not installed>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nps.__version__\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'3.4.1'\n```\n:::\n:::\n\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}