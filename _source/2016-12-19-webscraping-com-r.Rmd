---
layout: post
title: 'Webscraping com R'
date : 2016-12-19
tags: [r]
--- 

# Introdução

Webscarping é uma técnica utilizada para obter dados provenientes de sites da
internet. Usa-se webscraping quando é necessário obter informações que não estão 
disponíveis em um banco de dados público, mas que podem ser obtidas por meio de uma
página da web. 

Geralmente páginas da internet podem ser considerados dados semi-estruturados, ou seja,
esses dados possuem uma estrutura relativamente bem definida, no entanto a estrutura é longe 
de ser a ideal para fazer análises. Webscraping transforma essa informação semi-estruturada
em informações que podem ser consideradas estruturadas.

Para aprender a fazer webscrapping é necessário entender um pouco do protocolo
HTTP e como funcionam requisições desse tipo e também a estrutura de arquivos html
e sua relação com arquivos css.

Neste post vamos falar sobre webscraping separando nessas duas partes:

- Como obter a página web (baixar)
- Como obter os dados que estão na página web obtida (raspagem)

Com o que falaremos aqui, será possível fazer webscrapping de grande parte dos sites
da internet, no entanto, não trataremos aqui de webscraping de sites que possuem 
muitas informações carregadas em *client-side* via javascript pois, neste caso, 
a abordagem precisa ser mais complexa, as vezes envolvendo a emulação de um browser.

# Obtendo as páginas desejadas

HTTP como é abreviado o Hypertext Transfer Protocol, é a base para a comunicação
por meio da Internet. O HTTP funciona basicamente da seguinte forma: o cliente 
envia uma mensagem e o servidor envia uma resposta. Essa mensagem possui um cabeçalho (header)
e um corpo. O HTTP possui 8 métodos que determinam o que o servidor faz com o URL
fornecido. A maioria dos sites utiliza apenas `GET` ou `POST`.

O `GET` é o mais simples deles. Geralmente, essas requisições não possuem corpo,
e a respota é um arquivo `.html`. No R, uma requisição GET, pode ser realizada
usando a função `GET` do pacote `httr`.

```{r}
library(httr)
res <- GET("https://pt.wikipedia.org/wiki/Hypertext_Transfer_Protocol")
```

Na Wikipedia, por exemplo, o nome da página que você deseja acessar é passado como
parte do URL, como acima, queremos consultar a página sobre HTTP e passamos o 
nome desta página logo após a barra. Esse padrão se repete em muitos sites. 

Veja por exemplo uma busca no site da Folha de São Paulo. Vamos usar a opção de
salvar o arquivo no disco. Dessa forma, você poderá abrir o arquivo html gerado 
no seu próprio browser. 

```{r}
res <- GET("http://search.folha.uol.com.br/?q=busca", write_disk("busca_folha.html"))
```

Se você abrir no browser, obterá um resultado parecido com esse.

![busca_folha](../images/busca_folha.jpeg)

Você notará que a aparência é diferente de quando você abre pelo URL direto.
Isso acontece porque quando você acessa um site pelo seu browser, ele não faz apenas
uma requisição. Geralmente, ele faz dezenas de requisições, entre elas ele estará
buscando os arquivos de estilo, responsáveis por customizar a aparência dos sites. 
Mas, tudo bem, para fazer webscraping, você só precisa da estrutura dada pelo arquivo `html'.
Verifique que todo o texto da busca está -lá, só ficou faltando a formatação. 

Assim como na Wikipedia, o site da Folha de São Paulo entende requisições `GET`
para uma busca. As palavras chave da busca são passadas por meio do parâmetro `q`
da URL. Uma forma mais elegante de fazer uma busca desse tipo usando o `httr` é 
usar o parâmetro `query`. Exemplo:

```{r}
res <- GET("http://search.folha.uol.com.br/", query = list(q = "busca"))
```

O próprio `httr` tomará cuidado de adicionar estes parâmetros à URL que será consultada. 
Isso evitará muitos `paste` ou `sprintf` para cocatenar as strings, assim como irá
ajudar quando as palavras chaves contiverem carcateres especiais, que precisam ser
pre-processados antes de serem passados para a URL.

Concluindo, requisições `GET` são mais simples, pois passam os parâmetros por meio
da URL. Agora considere o [site da ONS (Operador Nacional do Sistema Elétrico).](http://www.ons.org.br/historico/geracao_energia_out.aspx).

Quando você acessa esse site, aparece apenas um formulário, como o abaixo.

![formulario_ons](../images/formulario_ons.png)

Ao preencher o formulário e clicar no botão *Consultar*, a URL não muda, mas o que 
aparece no browser, sim. Esse é um exemplo de obtenção de informações do servidor
por meio do método `POST`. Os parâmetros foram enviados para o servidor dentro do 
corpo da mensagem de requisição, ao invés da URL, ficando menos transparentes para o 
usuário.

Fazer essas consultas usando o R pode ser um pouco complicado, principalmente porque muitos 
sites enviam diversos parâmetros de forma implícita, sem que você saiba o que eles 
significam. Uma boa forma de identificar todos os parâmetros que foram enviados é pelo 
*Developer Tools* do Google Chrome. Para isso, vá para a página do formulário, e 
aperte F12. Ou clique em qualquer lugar da página com o botão direito e vá para *Inspect*. 
Em seguida clique na aba *Network*. 

Com o *Developer Tools* aberto, selecione as opções no formulário e clique em consultar. 
Você verá algo parecido com a figura abaixo.

![developer_tools_1](../images/developer_tools-1.png)

Clique nesta primeira linha, que está destacada e vá para a aba *Headers*, conforme a próxima figura.

![developer_tools_2](../images/developer_tools-2.PNG)

Desça mais um poquinho o e encontree a sessão *Form Data*:

![developer_tools_3](../images/developer_tools-3.PNG)

Esses são os parâmetros e valores que são passados para o servidor por meio do
método `POST`. Agora a consulta fica simples de ser realizada pelo R, usando a 
função `POST` do pacote `httr`.






