---
layout: post
title: 'Definindo um modelo estatístico como uma classe R6'
date : 2016-11-29
tags: [r]
--- 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Este post tenta definir uma ideia, mais teórica do que prática, de como definir um
modelo estatístico de forma organizada e reproduzível em uma linguagem de computador.
Como este blog é sobre R, vamos usar o próprio R.

Essa ideia ainda não está pronta, talvez nunca fique pronta também, mas decidi 
escrevê-la para facilitar o raciocínio.

Suponha um modelo de regressão linear, do tipo mais simples. No R ajustamos este
modelo da seguinte forma.

```{r, message=FALSE}
library(tidyverse)
df <- data_frame(
  x = rnorm(100),
  y = 2*x + runif(100, -.5, .5)
)
reg <- lm(y ~ x, data = df)
```

Com o modelo ajustado, você pode usar a função `predict` para prever novas 
observações usando este modelo.

```{r, eval=FALSE}
predict(reg, newdata = data_frame(x = rnorm(100)))
```

Essa forma usa o classes de um tipo de OO chamado S3. Esse método é, de longe, o mais utilizado dentro do R. Praticamente todas as funções simples que você já usou
são métodos S3. Veja por exemplo o código da função `predict`:

```{r}
predict
```

Esse `UseMethod("predict")` está dizendo: "use o método `predict` para a classe
do objeto que está sendo predito".

O problema desta abordagem surge quando você está tentando definir uma API única
para acessar e ajustar diversos tipos diferentes de modelos estatísticos como fazem o
`caret` e o `mlr`. 

No `caret`, uma única função `train` é usada para treinar os modelos. O modelo
é escolhido por meio do parâmetro `method` e passamos os hiperparâmetros do 
algoritmo pelo parâmetro `tuneGrid`. Se nenhum argumento é passado para o `tuneGrid`
o `caret` usa um grid de parâmetros pré-estabelecidos.
As desvantagens desta abordagem são:

* Não fica claro quais são os hiperparâmetros que serão utilizados.
* Não é possível fazer _autocompletion_ dos nomes dos parâmetros. (Apesar de parecer simples, isso aumenta muito a produtividade.)

A outra abordagem bastante conhecida é a utilizada pelo pacote `mlr`. O `mlr` define
algumas classes importantes como a [`Learner`](https://www.rdocumentation.org/packages/mlr/versions/2.9/topics/makeLearner?)
a [`Task`](https://rdrr.io/cran/mlr/man/Task.html). Um `Learner` é próximo do que
acredito ser uma boa definição de um modelo estatístico, no entanto, ele tem as seguintes
desvantagens:

* Os argumentos são passados por meio de uma lista pelo parâmetro `par.vals` ou
por meio de  elipses (`...`), por isso não é possível usar _autocompletion_.
* Por não ser um parâmetro explicito de uma função, esses parâmetros acabam ficando
muito mal documentados, apesar do `mlr` incentivar a documentação. Se os parâmetros
fossem parâmetros de função, seriam obrigatoriamente documentados para que o pacote
pudesse ser publicado no CRAN.

O `mlr` apesar de possuir uma definição relativamente formal de classes, utiliza
classes do tipo S3. Veja [aqui](https://mlr-org.github.io/mlr-tutorial/devel/html/create_learner/index.html)
como define-se um modelo dentro do `mlr`. 

Primeiro define-se uma função que cria o `Learner`:

```{r eval = FALSE}
makeRLearner.classif.lda = function() {
  makeRLearnerClassif(
    cl = "classif.lda",
    package = "MASS",
    par.set = makeParamSet(
      makeDiscreteLearnerParam(id = "method", default = "moment", values = c("moment", "mle", "mve", "t")),
      makeNumericLearnerParam(id = "nu", lower = 2, requires = quote(method == "t")),
      makeNumericLearnerParam(id = "tol", default = 1e-4, lower = 0),
      makeDiscreteLearnerParam(id = "predict.method", values = c("plug-in", "predictive", "debiased"),
        default = "plug-in", when = "predict"),
      makeLogicalLearnerParam(id = "CV", default = FALSE, tunable = FALSE)
    ),
    properties = c("twoclass", "multiclass", "numerics", "factors", "prob"),
    name = "Linear Discriminant Analysis",
    short.name = "lda",
    note = "Learner param 'predict.method' maps to 'method' in predict.lda."
  )
}
```

Em seguida definem-se duas funções: uma para treinar o classificador e outra para
prever novos valores:

```{r, eval=FALSE}
trainLearner.classif.lda = function(.learner, .task, .subset, .weights = NULL, ...) {
  f = getTaskFormula(.task)
  MASS::lda(f, data = getTaskData(.task, .subset), ...)
}
```

```{r}
predictLearner.classif.lda = function(.learner, .model, .newdata, predict.method = "plug-in", ...) {
  p = predict(.model$learner.model, newdata = .newdata, method = predict.method, ...)
  if (.learner$predict.type == "response") 
    return(p$class) else return(p$posterior)
}
```

Essa estrutura é bem interessante. É intuitiva e parece ser bem formal. 
Chego aqui na motivação de se definir um modelo usando classes R6. A sugestão é, 
por exemplo, para a análise discriminante linear, definí-la da seguinte forma:

```{r}
library(R6)

classif_lda <- R6Class("classif_lda",
  public = list(
    
    method = NULL,
    nu = NULL,
    tol = NULL,
    predict.method = NULL,
    CV = NULL,
    
    initialize = function(
      method = "moment", nu = NULL, tol = 1e-4, 
      predict.method = "plug-in", CV = FALSE
    ) {
      self$method <- method
      self$nu <- if(method == "t") nu else NULL
      self$tol <- tol
      self$predict.method <- predict.method
      self$CV <- CV
      return(self)
    },
    
    fit = function(X, Y) {
      MASS::lda(
        x = X, grouping = Y, method = self$method, nu = self$nu,
        tol = self$tol, CV = self$CV
      )
    },
    
    predict = function(X, fit) {
      p <- predict(fit, newdata = X, method = self$predict.method)
      p$posterior
    }
    
  )
)
```

* Todos os parâmetros são declarados com o valor `NULL`. 
* O método de inicialização estabelece alguns `defaults` para os parâmetros, mas
permite especificar todos eles.
* Definimos um método `fit` que retorna o modelo ajustado usando os parâmetros 
definidos na inicialização do modelo. Esse método recebe como argumentos uma matriz
X com as covariáveis e um vetor/matriz Y com a resposta.
* Definimos um método `predict` que retorna a predição. Esse método usa os argumentos
definidos na inicialização do modelo e recebe ainda uma matriz X (que você deseja prever)
e o modelo ajustado `fit`.

Em seguida, funções genéricas podem ser utilizadas para ajustar qualquer modelo.
Por exemplo:

```{r}
train <- function(X, Y, model) {
  model$fit(X, Y)
}
```

A função `train` poderia receber instruções mais complexas como fazer cross-validation,
calcular algumas medidas de acerto, etc.








