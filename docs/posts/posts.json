[
  {
    "path": "posts/2021-03-31-gh-actions-self-hosted/",
    "title": "Self-created custom runners with Github Actions",
    "description": "In this article we describe the approach we are using to \ncreate and manage custom GPU accelerated Windows instances\nto run CI workflows in the torch project.",
    "author": [
      {
        "name": "Daniel Falbel",
        "url": "https://github.com/dfalbel"
      }
    ],
    "date": "2021-03-31",
    "categories": [],
    "contents": "\nGitHub Actions is a tool to automate CI/CD workflows. In the torch for R project besides the hosted runners offered by GitHub that allow us to test torch in all major platforms, we need to test our code in GPU accelerated systems.\nGitHub Actions doesn’t offer GPU accelerated hosted runners but allows one to easily add self-hosted runners to a repository.\nAdding a self-hosted runner to a repository is a relatively task when the machine that is going to run the workflows is persistent, ie. the machine is turned on most of the time expect for a few restarts or etc.\nHowever GPU’s are quite expensive and most cloud offerings charge ~$250 monthly for a 24h - 7/7 machine equipped with an NVIDIA Tesla K80 GPU. THis is not nice specially because the instance would be idle for a large fraction of this period.\nThe ideal solution for us would be to spin up a GPU equipped ephemeral instance every time we would like to run our workflow and turn it off once it’s finished. If we were to do it on Linux there are a few posts that help configuring ephemeral self-hosted runners for GitHub Actions. Specifically, this series by Stephen O’Brien is great. Docker and nvidia-docker helps a lot here!\nOn Windows though, there’s no support for nvidia-docker, so we had to build another custom solution.\nOverview\nOverview diagramOur workflow will have 3 chained jobs that will do the following:\nCreate virtual machines on Google Cloud Platform, install the Github Actions runner and register them trough the GH Actions API.\nThe machines that were created in step .1 will take on the CI jobs. Eg running R CMD CHECK. This can possibly be a matrix of jobs.\nDelete the VM instances and unregister the runners from HJ Actions.\n1. Creating runners\nFirst step to create the runners was to create a machine image with basic software pre-installed - this is similar to what GH Actions has for the hosted runners here.\nTo do this we first created a VM instance in Google Cloud and manually installed the CUDA toolkit versions, CUDNN libraries, CMake, Visual Studio Community (for the vsc compiler) and Git.\nOnce you have manually installed everything you can create the machine image. I used the web UI of google cloud console, mostly following this tutorial. It’s basically selecting the source VM (the one we already installed the basic software) and giving a name to the machine image. In my case it was “cuda-v1” or something like that.\nNow that we have the machine image we can create the ‘start-runners’ job in the GitHub workflow .yaml file.\nThe full job description looks like this and we describe each step in code comments:\nstart-runner:\n    runs-on: ubuntu-18.04\n    steps:\n    \n    # Installs the gcloud SDK and set's up the creadentials\n    # We are are going to use the SDK to create the VM instances.\n    - name: Set up Cloud SDK\n      uses: google-github-actions/setup-gcloud@master\n      with:\n        project_id: ${{ secrets.GCP_PROJECT_ID }}\n        service_account_key: ${{ secrets.GCP_APPLICATION_CREDENTIALS }}\n        export_default_credentials: true\n    \n    # Creates the token used to register a new self-hosted runner via\n    # the GH actions API.\n    - name: Create registration token\n      uses: actions/github-script@v3\n      id: token\n      with:\n        github-token: ${{secrets.GH_TOKEN}}\n        result-encoding: string\n        script: |\n          const result = await github.actions.createRegistrationTokenForRepo({\n            owner: 'mlverse',\n            repo: 'torch'\n          });\n          console.log(result)\n          return result.data.token\n          \n    # In this step we create an startup script that is run once\n    # when the VM instance is created.\n    # The startup script we create here is responsible for downloading\n    # and installing the actions runner system and registering it.\n    # This script will create a runner with a label 'run-${{ github.run_number}}'.\n    # We are going to use this information to select the runner that will be used\n    # for runnig the tests in step 2.\n    # We used Power Shell (.ps1) script but it could also be a `.bat` file.\n    - name: Create the startup script\n      run: |\n        touch s.ps\n        echo \"mkdir C:\\actions-runner; cd C:\\actions-runner\" >> s.ps\n        echo \"Invoke-WebRequest -Uri https://github.com/actions/runner/releases/download/v2.277.1/actions-runner-win-x64-2.277.1.zip -OutFile actions-runner-win-x64-2.277.1.zip\" >> s.ps\n        echo 'Add-Type -AssemblyName System.IO.Compression.FileSystem ; [System.IO.Compression.ZipFile]::ExtractToDirectory(\"$PWD/actions-runner-win-x64-2.277.1.zip\", \"$PWD\")' >> s.ps\n        echo \"./config.cmd --url https://github.com/mlverse/torch --token ${{ steps.token.outputs.result }} --name 'runner-${{ github.run_number }}' --labels 'run-${{ github.run_number}}' --unattended\" >> s.ps\n        echo 'Start-Process -FilePath \"./run.cmd\"' >> s.ps\n        \n    # Now we can create the VM instance on GCP using the `gcloud` SDK\n    # that we already installed.\n    # The `source-machine-image` parameter describes which machine\n    # will be used for the VM you create. You should pass the same\n    # name as you used when you created the machine image.\n    # The `metadata-from-file` parameter is telling gcloud to copy\n    # the startup scrip we just created and ru it when the machine starts.\n    # Other parameters are related to the resources you want your machine\n    # to have. In our case we used a n1-standard-8 machine equipped with a\n    # NVIDIA Tesla K80 GPU.\n    - name: Create instance\n      run: | \n        gcloud components install beta --quiet\n        gcloud beta compute --project=rstudio-cloudml instances create runner-${{github.run_number}} \\\n          --zone=us-central1-a \\\n          --machine-type=n1-standard-8 \\\n          --accelerator=type=nvidia-tesla-k80,count=1 \\\n          --source-machine-image cuda-v8 \\\n          --network-interface network=default \\\n          --metadata-from-file windows-startup-script-ps1=s.ps\n    # It might take some time for the startup script to run and we want\n    # to wait for a couple of minutes before starting the next job, because it\n    # requires that the self-hosted runner is already registered.\n    - name: Wait for runner registration\n      run: |\n        sleep 2m 30s\n2. Running the tests\nThis job is where we actually define what we want to run in the VM we just created and registered.\nWe just want to run R CMD CHECK in our package to make sure everything works on NVIDIA GPU’s on Windows.\nThe workflow description is pretty much the same as the one we use in the hosted runner, however we condition the run-on so this job runs in the runner we just created.\nThe job looks like the chunk below. Comments in the important parts.\nwindows-gpu:\n    # this is important so this job only runs after a successful run of the \n    # `start-runner` job\n    needs: ['start-runner']\n    strategy:\n      fail-fast: false\n      matrix:\n        r_version: [\"release\"]\n        cuda: [\"11.1\"]\n\n    # Here we tell GH actions to run this job in a runner labeled \n    # 'run-${{ github.run_number}}' which is exactly the runner we\n    # created and registered in step 1.\n    # Everything below here is identical to the job we run on the\n    # GH Actions hosted runner.\n    runs-on: [self-hosted, windows, 'run-${{ github.run_number}}']\n    \n    name: 'Windows | CUDA: ${{ matrix.cuda }}'\n    timeout-minutes: 120\n    env:\n      R_REMOTES_NO_ERRORS_FROM_WARNINGS: true\n      INSTALL_TORCH: 1\n      TORCH_LOG: 2\n      TORCH_TEST: 1\n      TORCH_INSTALL: 1\n      CUDA: ${{ matrix.cuda }}\n      \n    steps:\n      - uses: actions/checkout@v2\n      - uses: r-lib/actions/setup-r@master\n        with:\n          r-version: ${{ matrix.r_version }}\n      - uses: r-lib/actions/setup-pandoc@master\n      - name: Install dependencies\n        run: | \n          Rscript -e \"options(repos=structure(c(CRAN='https://cloud.r-project.org/'))); install.packages(c('remotes', 'rcmdcheck', 'fs'))\" -e \"remotes::install_deps(dependencies = TRUE)\"\n      - name: Build lantern and get libtorch\n        if: contains( github.event.pull_request.labels.*.name, 'lantern')\n        run: | \n          Rscript tools/buildlantern.R\n      - name: Check\n        run:  |\n          withr::with_makevars(list(MAKEFLAGS=\"-j8\"), {\n            rcmdcheck::rcmdcheck(args = c(\"--no-multiarch\", \"--no-manual\"), error_on = \"error\", check_dir = \"check\")\n          })\n        shell: Rscript {0}\n3. Clean up resources\nThis step runs after the test job runs and is responsible for correctly cleaning up the resources, ie. deleting the VM instance on google cloud and removing the runner in GH Actions UI.\nWe do this using the following job:\ndelete-runner:\n    # This if statement is important so this jobs runs even if the testing fails.\n    # By default, GH Actions would skip it if the testing failed.\n    if: ${{ success() || failure() || cancelled() }}\n    # This defines that this job will run after the testing job and after the job\n    # that creates the instances.\n    needs: ['windows-gpu', 'start-runner'] \n    runs-on: ubuntu-18.04\n    steps:\n    # Again we setup gcloud\n    - name: Set up Cloud SDK\n      uses: google-github-actions/setup-gcloud@master\n      with:\n        project_id: ${{ secrets.GCP_PROJECT_ID }}\n        service_account_key: ${{ secrets.GCP_APPLICATION_CREDENTIALS }}\n        export_default_credentials: true\n    # This used the the gcloud CLI to delete the instance with name that we\n    # gave in the startup script.\n    - name: Delete runner instance\n      run: |\n        gcloud compute --project=rstudio-cloudml instances delete runner-${{github.run_number}} --zone=us-central1-a\n    # This removes the runner from the GH self-hosted registry.\n    # This is not strictly necessary as GH actions seems to delete unreachable\n    # runners after some time but looks like good practice.\n    - name: Delete runner from GH\n      uses: actions/github-script@v3\n      id: token\n      with:\n        github-token: ${{secrets.GH_TOKEN}}\n        result-encoding: string\n        script: |\n          const runners = await github.actions.listSelfHostedRunnersForRepo({\n            owner: 'mlverse',\n            repo: 'torch'\n          });\n          \n          const runner_id = runners.data.runners.filter((runner) => {\n            return runner.name === 'runner-${{ github.run_number }}';\n          })[0].id\n          \n          await github.actions.deleteSelfHostedRunnerFromRepo({\n            owner: 'mlverse',\n            repo: 'torch',\n            runner_id: runner_id\n          });\nFim\nIn this post we described our approach for self-hosted runners with GPU’s on Windows. It’s not trivial and this post is far from being detailed. Feel free to reach out if you have other questions or if we can help with anything. The full workflow is here.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-04-12T17:23:48-03:00",
    "input_file": {}
  }
]
